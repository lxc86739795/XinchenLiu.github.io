![Image](./images/photo1_240.jpg)

## About Me
I am currently a researcher at JD AI Research working with Dr. [Wu Liu](https://liuwu.weebly.com/) and Dr. [Tao Mei](https://taomei.me/).
I received my Ph. D. degree in computer science in Beijing Key Lab of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, in 2018. 
My supervisor is Prof. [Huadong Ma](https://int.bupt.edu.cn/content/content.php?p=2_4_266). 
My research interests include multimedia computing, computer vision, and their applications in retail.

* Email: liuxinchen1 at jd dot com

* Github: [lxc86739795](https://github.com/lxc86739795)

## Publications ([dblp](https://dblp.uni-trier.de/pers/hd/l/Liu:Xinchen) [Google Scholar](https://scholar.google.com/citations?user=31Dv7M0AAAAJ&hl=en))

- **Xinchen Liu**, Meng Zhang, Wu Liu, Jingkuan Song, Tao Mei:
_BraidNet: Braiding Semantics and Details for Accurate Human Parsing_. ACM MM 2019. (Accepted)

- **Xinchen Liu**, Wu Liu, Meng Zhang, Jingwen Chen, Lianli Gao, Chenggang Yan, Tao Mei:
_Social Relation Recognition from Videos via Multi-scale Spatial-Temporal Reasoning_. CVPR 2019.

- **Xinchen Liu**, Wu Liu, Huadong Ma, Shuangqun Li:
_PVSS: A Progressive Vehicle Search System for Video Surveillance Networks_. J. Comput. Sci. Technol. 34(3): 634-644 (2019)

- Meng Zhang, **Xinchen Liu**, Wu Liu, Anfu Zhou, Huadong Ma, Tao Mei:
_Multi-Granularity Reasoning for Social Relation Recognition from Images_. ICME 2019. (Accepted)

- **Xinchen Liu**, Wu Liu, Tao Mei, Huadong Ma:
_PROVID: Progressive and Multimodal Vehicle Reidentification for Large-Scale Urban Surveillance_. IEEE Trans. Multimedia 20(3): 645-658, (2018) (**TMM Multimedia Prize Paper Award 2019**)

- **Xinchen Liu**, Wu Liu, Huadong Ma, Shuangqun Li:
_A Progressive Vehicle Search System for Video Surveillance Networks_. BigMM 2018: 1-7

- Wenhui Gao, **Xinchen Liu**, Huadong Ma, Yanan Li, Liang Liu:
_MMH: Multi-Modal Hash for Instant Mobile Video Search_. MIPR 2018: 57-62

- Wu Liu, **Xinchen Liu**, Huadong Ma, Peng Cheng:
_Beyond Human-level License Plate Super-resolution with Progressive Vehicle Search and Domain Priori GAN_. ACM Multimedia 2017: 1618-1626

- Shuangqun Li, **Xinchen Liu**, Wu Liu, Huadong Ma, Haitao Zhang:
_A discriminative null space based deep learning approach for person re-identification_. CCIS 2016: 480-484

- **Xinchen Liu**, Wu Liu, Tao Mei, Huadong Ma:
_A Deep Learning-Based Approach to Progressive Vehicle Re-identification for Urban Surveillance_. ECCV (2) 2016: 869-884

- **Xinchen Liu**, Wu Liu, Huadong Ma, Huiyuan Fu:
_Large-scale vehicle re-identification in urban surveillance videos_. ICME 2016: 1-6 (**Best Student Paper Award**)

- **Xinchen Liu**, Huadong Ma, Huiyuan Fu, Mo Zhou:
_Vehicle Retrieval and Trajectory Inference in Urban Traffic Surveillance Scene_. ICDSC 2014: 26:1-26:6

## Activities
Journal Reviewer: IEEE TPAMI, IEEE TMM, IEEE TIP, IEEE TITS, ACM TOMM, IoTJ, MTAP, ...

Conference Reviewer: CVPR, ACM MM, ICME, ICASSP, ICIP, ...

## Awards and Honors
IEEE TMM Multimedia Prize Paper Award, 2019, for the paper "_PROVID: Progressive and Multimodal Vehicle Reidentification for Large-Scale Urban Surveillance_"

CVPR 2019 LIP Challenge, Track 3 Multi-Person Human Parsing, 2nd Award

CVPR 2018 LIP Challenge, Track 1 Single-Person Human Parsing, 2nd Award

IEEE ICME Best Student Paper Award, 2016, for the paper "_Large-scale vehicle re-identification in urban surveillance videos_"

## Research

### Vehicle Search in Larve-scale Surveillance Networks ([More Details](http://vehiclereid.github.io/VeRi/))
Compared with person re-identification, which has concentrated attention, vehicle re-identification is an important yet frontier problem in video surveillance and has been neglected by the multimedia and vision communities. 
Since most existing approaches mainly consider the general vehicle appearance for re-identification while overlooking the distinct vehicle identifier, such as the license number plate, they attain suboptimal performance. 
In this work, we propose PROVID, a PROgressive Vehicle re-IDentification framework based on deep neural networks. 
In particular, our framework not only utilizes the multi-modality data in large-scale video surveillance, such as visual features, license plates, camera locations, and contextual information, but also considers vehicle re-identification in two progressive procedures: coarse-to-fine search in the feature domain, and near-to-distant search in the physical space. 
Furthermore, to evaluate our progressive search framework and facilitate related research, we construct the VeRi dataset, which is the most comprehensive dataset from real-world surveillance videos. 
It not only provides large numbers of vehicles with varied labels and sufficient cross-camera recurrences but also contains license number plates and contextual information. 
Extensive experiments on the VeRi dataset demonstrate both the accuracy and efficiency of our progressive vehicle re-identification framework.

&ensp;&ensp;&ensp;&ensp;![Image](./images/VeRi_240.png)&ensp;&ensp;![Image](./images/VeRi2_240.png)

### Fine-grained Human Parsing
This paper focuses on fine-grained human parsing in images. 
This is a very challenging task due to the diverse person appearance, semantic ambiguity of different body parts and clothing, and extremely small parsing targets. 
Although existing approaches can achieve significant improvement by pyramid feature learning, multi-level supervision, and joint learning with pose estimation, human parsing is still far from being solved. 
Different from existing approaches, we propose a Braiding Network, named as BraidNet, to learn complementary semantics and details for fine-grained human parsing. 
The BraidNet contains a two-stream braid-like architecture.
The first stream is a semantic abstracting net with a deep yet narrow structure which can learn semantic knowledge by a hierarchy of fully convolution layers to overcome the challenges of diverse person appearance. 
To capture low-level details of small targets, the detail-preserving net is designed to exploit a shallow yet wide network without down-sampling, which can retain sufficient local structures for small objects. 
Moreover, we design a group of braiding modules across the two sub-nets, by which complementary information can be exchanged during end-to-end training. 
Besides, in the end of BraidNet, a Pairwise Hard Region Embedding strategy is propose to eliminate the semantic ambiguity of different body parts and clothing. 
Extensive experiments show that the proposed BraidNet achieves better performance than the state-of-the-art methods for fine-grained human parsing.

  ![Image](./images/BraidNet1_400.png)    ![Image](./images/BraidNet2_400.png)

### Social Relation Recognition 
Discovering social relations, e.g., kinship, friendship, etc., from visual contents can make machines better interpret the behaviors and emotions of human beings. 
Existing studies mainly focus on recognizing social relations from still images while neglecting another important mediaâ€”video. 
On the one hand, the actions and storylines in videos provide more important cues for social relation recognition. 
On the other hand, the key persons may appear at arbitrary spatial-temporal locations, even not in one same image from beginning to the end. 
To overcome these challenges, we propose a Multi-scale Spatial-Temporal Reasoning (MSTR) framework to recognize social relations from
videos. 
For the spatial representation, we not only adopt a temporal segment network to learn global action and scene information, but also design a Triple Graphs model to capture visual relations between persons and objects. 
For the temporal domain, we propose a Pyramid Graph Convolutional Network to perform temporal reasoning with multi-scale receptive fields, which can obtain both long-term and short-term storylines in videos. 
By this means, MSTR can comprehensively explore the multi-scale actions and story-lines in spatial-temporal dimensions for social relation reasoning in videos. 
Extensive experiments on a new large-scale Video Social Relation dataset demonstrate the effectiveness of the proposed framework.
The dataset can be download from [BaiduPan (~57GB)](https://pan.baidu.com/s/1Rnk5oMJlLjAHi0vEgzqEWg).

![Image](./images/ViSR1_240.png)![Image](./images/ViSR2_240.png)

_last Update: **July, 2019**_
